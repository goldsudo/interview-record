java8有哪些新特性?lamda与stream了解吗？
介绍下java的nio？
io中缓冲区的作用?为什么缓冲区可以加块读取速度？
介绍下netty？
了解java的深拷贝与浅拷贝？
详细描述下java中的hashmap实现原理（附加：jdk1.8之前与1.8之后，hashmap的实现有什么区别）？
hashmap中的loadFactor的取值大小对hashmap有什么影响？
hashmap中put一万个元素应该怎么做？
hashmap、hashtable、concurrenthashmap的区别？（附加：concurrenthashmap的实现原理）？
treemap、linkedhashmap的作用？
hashset的实现原理？
arraylist、linkedlist、vector的区别？
如何判断一个对象是否可被gc？
jvm内存结构？
jvm的gc原理，每个内存区域使用什么gc算法？
java的new关键字在jvm层面都做了哪些事？
知道哪些jvm垃圾收集器？
java内存模型？（注意与jvm内存结构不是一回事）
jvm是如何实现一次编译到处运行的?
十个线程同时++i会出现什么问题？为什么？如何解决?
automicinteger的实现原理？
如何在运行时估算一个java对象的大小？
有哪些可以监控jvm内存使用情况的工具?这些工具的实现原理？
线程和进程的区别？
java创建一个线程的几种方式？（Thread、Runnable、Callable、ExecutorService线程池）
悲观锁、乐观锁、自旋锁？
独占锁、共享锁？
偏向锁、轻量级锁、重量级锁？
介绍下volatile与synchronized关键字的作用？
tomcat的实现原理？
序列化和反序列化？（protostuff可以减小对象序列化后的大小）
线程有哪些状态？
线程阻塞分为哪几种情况？
有哪些类型的线程池构造方法？
线程池有哪些重要的配置？
线程池中的线程数量达到最大值后会怎样？
业务高峰过后，线程池中的线程数量多余的话会怎样？
线程池容量能不能动态调整？

java8有哪些新特性?lamda与stream了解吗？
答：
（1）
	接口中可以用default关键字实现公用的方法
	只声明一个方法的接口可以作为函数式接口
	Function接口
	labmda表达式
	stream流式编程（分为串行流stream和并行流paralleStream）
	新的日期与时间类LocalDate、LocalTime、LocalDateTime
（2）
	lamda可以实现函数式编程，减少代码量
	stream提供了一种更优雅的遍历以及处理集合的编程方式，搭配lamda使用效果更好
	stream还采用了惰性计算，使程序运行变得非常高效
（3）
	函数式编程思维的例子：
	命令式编程：
	int a,b,r;
	void add_abs(){
		scanf("%d %d",&a,&b);
		r = abs(a)+abs(b);
		printf("%d",r);
	}
	有点函数式编程的意思，但还不太函数式的编程：
	int add_abs(int a,int b){
		int r = 0;
		r += abs(a);
		r += abs(b);
		return r;
	}
	标准的函数式编程，用函数的组合表示程序的组合：
	int add_abs(int a,int b){
		return abs(a)+abs(b);
	}

介绍下java的nio？
答：
	nio由jdk1.4引入，提供了高速的、面向块的IO，而原来的IO是面向流（一次移动一个字节）的。
	不过目前java.io.* 中的IO类已经以 NIO 为基础重新实现了，所以现在它可以利用 NIO 的一些特性。
	nio的主要特性为channle通道、buffer缓冲区、selector轮询管理多个channel:
	buffer:
		Buffer是一个对象， 它包含一些要写入或者刚读出的数据。 在 NIO 中加入 Buffer 对象，体现了新库与原 I/O 的一个重要区别。在面向流的 I/O 中，您将数据直接写入或者将数据直接读到 Stream 对象中。
		在 NIO 库中，所有数据都是用缓冲区处理的。在读取数据时，它是直接读到缓冲区中的。在写入数据时，它是写入到缓冲区中的。
		缓冲区实质上是一个数组，通常它是一个字节数组，但是也可以使用其他种类的数组，buffer支持所有的java类型，比如ByteBuffer，CharBuffer，IntBuffer，DoubleBuffer等。
		但是一个缓冲区不仅仅是一个数组:
		buffer中的重要属性，position当前位置，limit当前数量，capacity最大容量
		buffer中的重要方法：	put()将position值增加1，代表新写入一个
							flip()将 limit 设置为当前 position，将 position 设置为 0，代表可以读取数据了。
						   clear()将 limit 设置为与 capacity 相同,设置 position 为 0，代表可以写入数据了。
	channel:
		Channel也是一个对象，可以通过它读取和写入数据。拿 NIO 与原来的 I/O 做个比较，通道就像是流。
		通道与流的不同之处在于通道是双向的。而流只是在一个方向上移动(一个流必须是 InputStream 或者 OutputStream 的子类)， 而 通道 可以用于读、写或者同时用于读写。
	nio的工作流程：
		读取数据时先创建一个缓冲区，然后让通道将数据读到这个缓冲区中；
		写入数据时先创建一个缓冲区，用数据填充它，然后让通道用这些数据来执行写入操作。
		总之无论读写，都需要使用缓冲区。
	selector：
		selector可使一个单独的线程管理多个Channel，open方法可创建Selector，register方法向多路复用器器注册通道，可以监听的事件类型：读、写、连接、accept。注册事件后会产生一个SelectionKey：它表示SelectableChannel 和Selector 之间的注册关系，wakeup方法：使尚未返回的第一个选择操作立即返回，唤醒的原因是：注册了新的channel或者事件；channel关闭，取消注册；优先级更高的事件触发（如定时器事件），希望及时处理。
	NIO的服务端建立过程：
		Selector.open()：打开一个Selector；ServerSocketChannel.open()：创建服务端的Channel；bind()：绑定到某个端口上。并配置非阻塞模式；register()：注册Channel和关注的事件到Selector上；select()轮询拿到已经就绪的事件


io中缓冲区的作用?为什么缓冲区可以加块读取速度？
答：
	进行系统调用是耗时操作，但是无论读取多少数据，每次读取消耗的时间都几乎相等。所以读取等量的数据时，使用缓冲区可以减少系统调用的次数，从而减少调用的时间。
	将一堆砖头搬从A点搬到B点，直接用字节流的话，就是一块一块的搬，这个过程要执行很多次，效率上会很低。
	如果是采用缓冲流，那就相当于给你一个小推车，每次把小推车装满再搬，这样次数就会大大 降低，效率上也会有提升。
	原因就是因为io操作是很耗时的，如果每次只读一个字节，那么对于一个1KB的数据就要进行1000次IO，而如果使用一个1KB大小的缓冲区，那么就可以一次IO直接读完。
	（java中创建1KB大小对象的方法：new byte[1024] 1MB:new byte[1024*1024]）

介绍下netty？
答：
	一个高性能、异步事件驱动的NIO框架，它提供了对TCP、UDP和文件传输的支持；
	可使用接受/处理线程池，提高连接效率，对重连、心跳检测的简单支持；
	使用更高效的socket底层，对epoll空轮询引起的cpu占用飙升在内部进行了处理，避免了直接使用NIO的陷阱，简化了NIO的处理方式。

了解java的深拷贝与浅拷贝吗？
	1.直接赋值:A a1=a2，仅仅是复制了引用
	2.浅拷贝:调用clone 方法，这种情况下对象是被复制了，但是如果对象内部有引用字段，那么仍然指向同一个引用的对象
	3.深拷贝:可以自己实现clone方法，将所有引用字段都创建一个新的对象；
			也可以利用序列化和反序列化实现深拷贝。

详细描述下java中的hashmap实现原理（附加：jdk1.8之前与1.8之后，hashmap的实现有什么区别）？
答：
	（1）hashmap实现原理
	hashmap的底层是一个数组，数组的大小为2的整数次幂，原因是因为计算hash取模运算时，h & n-1的性能比 h%n的好，并且在n为2的整数次幂时，两者计算结果等价。
	hashmap的put分为两种情况：
		没有hash冲突，则直接放入数组的指定下标位置；
		有hash冲突，则插入数组指定下标处链表的头部，作为链表的新的头节点。
	hahsmap存在一个loadFactor用来控制何时进行扩容，默认为0.75，比如大小为16的hashmap，当存放元素超过16*0.75=12时，将进行resize。
	resize的操作会将当前数组的容量*2，然后重新计算所有元素在新数组中的位置即rehash。
	resize和rehash操作非常耗时且容易造成线程安全问题，因此建议在使用hashmap时，指定一个合适的初始化大小以避免扩容。
	hashmap不是线程安全的，但是提供了fail-fast机制，实现原理为hashmap中有个modcount的变量，当进行put操作时会将该变量值+1，在使用iterator遍历hashmap前，会将当前的modcount保存到一个副本expectedModCount中，然后在每次迭代时都去判断expectedModCount与modcount是否不一致了，如果是则代表在遍历的过程中有其他线程执行了put操作，此时将抛出ConcurrentModificationException。
	（2）1.8前后的hashmap
	1.8之前使用数组加链表实现
	1.8之后使用数组加红黑树实现

hashmap中的loadFactor的取值大小对hashmap有什么影响？
答：
	loadFactor是hashmap的扩容因子。
	扩容因子取值越大则代表hash表内的空间利用率越高，扩容的次数会减少，但是正因为hash中的元素变多了，导致hash碰撞的概率增加，这会影响查询的效率。
	扩容因子取值越小则会使得hash表内的空间利用率降低，扩容的次数会增多，但是由于hash中的元素变少了，使得hash碰撞的概率变小，可以提高查询的效率。

hashmap中put一万个元素应该怎么做？
答：
	首先应该评估一万个元素是否会OOM，不会的话再考虑如何put，否则服务器就挂了。
	如果想要用多线程put一万个元素，要求线程安全和效率兼顾的话不应使用hashmap或hashtable，而要用concurrenthashmap。
	然后是重点，由于hashmap存在resize操作，resize操作是很消耗资源的，为了避免在put一万个元素的过程中不进行resize，需要将hashmap的初始容量设置为比10000大的最小的2的n次幂。（要求2的n次幂是因为这能够加速计算hash的过程，不过hashmap内部对容量进行了控制，可以直接将容量设置为10000，然后hashmap会自动将容量计算成距离10000最近的2的n次幂）

hashmap、hashtable、concurrenthashmap的区别？（附加：concurrenthashmap的实现原理）？
答：
	（1）区别
	hashtable是hashmap的线程安全版，在会引起线程安全问题的操作上都增加了synchronized关键字，不过这样也牺牲了性能，在并发环境下很低效。
	因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。
	concurrenthashmap也是hashmao的线程安全版，与hashtable的区别是concurrenthashmap在保证线程安全的同时很好的兼顾了性能。
	（2）concurrenthashmap原理：
	concurrenthashmap使用一个数组存放2的N次方个segement，而segement的结构其实和hashmap一样，因此concurrenthashmap相当于一个二级哈希表，其内保存着若干个子哈希表。
	与hashtable不同，并发环境下concurrenthashmap仅需要锁住部分的segement，而不需要锁住所有数据。
	HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。
	不过concurrenthashmap这样的实现方式也引来新的难题，既然是分段锁，那么如何求size，难道还是要锁全部？
	ConcurrentHashMap的Size方法是一个嵌套循环，先尝试利用乐观锁解决问题，如果乐观锁无法解决，那么再采用悲观锁，大体逻辑如下：
		1.遍历所有的Segment。
		2.把Segment的元素数量累加起来。
		3.把Segment的修改次数累加起来。
		4.判断所有Segment的总修改次数是否大于上一次的总修改次数。如果大于，说明统计过程中有修改，重新统计，尝试次数+1；如果不是。说明没有修改，统计结束。
		5.如果尝试次数超过阈值，则对每一个Segment加锁，再重新统计。
		6.再次判断所有Segment的总修改次数是否大于上一次的总修改次数。由于已经加锁，次数一定和上次相等。
		7.释放锁，统计结束

treemap、linkedhashmap的作用？
答：（1）treemap
	TreeMap可以实现map中对象的排序，默认排序规则:按照key的字典顺序来排序(升序) 当然,也可以自定义排序规则:要实现Comparator接口。
	（2）linkedhashmap
	LinkedHashMap特性是可以按插入和访问顺序排序map中的对象。

hashset的实现原理？
答：
	hashset基于hashmap实现，仅使用了hashmap的key值来存放数据，而hashmap的value则全部都存放一个特殊的值 Object PRESENT = new Object()。

arraylist、linkedlist、vector的区别？
答：
	vector是线程安全版的arraylist。
	linkedlist是链表，其内的元素在内存中不是连续存放的。
	arraylist的查询性能极快，通过下标访问的话O(1)，在两头插入元素还好，但是在中间插入元素的性能很差，要进行很多交换操作。
	linkedlist的插入复杂度为O(1)，但是查找的性能为O(n)。

如何判断一个对象是否可被gc？
答：
	利用可达性判断：通过从gc-roots开始来进行扫描标记，如果一个对象到所有gc-roots之间都没有通路的话，代表该对象可被gc。
	gc-roots的选择标准：
		1.虚拟机栈（栈中的本地变量表）中引用的对象；
		2.方法区中类静态属性引用的对象；
		3.方法区中常量引用的对象；
		4.本地方法栈中JNI（即一般说的Native方法）引用的对象。

jvm内存结构？
答：
	jvm内存分为5各区域：程序计数器、虚拟机栈、本地方法栈，堆区，方法区
	1.程序计数器：
	当前线程所执行的字节码的行号指示器，用于实现循环以及分支。如果执行的是native方法，计数器是空值。
	该区域不会发生OOM。
	2.虚拟机栈：
	每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每一个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。
	该区域会引发stack-overflow(默认15层方法嵌套)和oom。
	3.本地方法栈：
	虚拟机栈起的作用一样，只不过方法栈为虚拟机使用到的Native方法服务。虚拟机规范并没有对这个区域有什么强制规定，因此在HotSpot虚拟机就干脆没有这块区域了，它和虚拟机栈是一起的。
	4.堆区：
	在虚拟机启动时创建，此内存唯一的目的就是存放对象实例。
	堆还可以细分为新生代和老年代，新生代细致一点还分为Eden区、From Survivior区、To Survivor。
	该区域会引发oom，也是jvm中gc最频繁的重点区域。
	对于该区域，jvm采用分代收集策略进行gc。
	5.方法区：
	用于存储虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据，虚拟机规范是把这块区域描述为堆的一个逻辑部分的，但实际它应该是要和堆区分开的。
	HotSpot中，方法区≈永久代。
	5.1运行时常量池:
	运行时常量池是方法区的一部分。Class文件中除了有类的版本信息、字段、方法、接口等描述信息外，还有一项信息就是常量池，用于存放编译期间生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中，另外翻译出来的直接引用也会存储在这个区域中。这个区域另外一个特点就是动态性，Java并不要求常量就一定要在编译期间才能产生，运行期间也可以在这个区域放入新的内容，String.intern()方法就是这个特性的应用。
	ps：直接内存
	想想还是把这块加上。直接内存并不是虚拟机运行时数据区的一部分，也不是Java虚拟机规范中定义的内存区域。但是这部分内存也被频繁地使用，而且也可能导致内存溢出问题。JDK1.4中新增加了NIO，引入了一种基于通道与缓冲区的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆中的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。显然，本机直接内存的分配不会受到Java堆大小的限制，但是，既然是内存，肯定还是会受到本机总内存（包括RAM、SWAP区）大小以及处理器寻址空间的限制。

jvm的gc原理，每个内存区域使用什么gc算法？
答：
	（1）新生代——minor gc
	新生代采用标记-复制算法，eden区和survivior区的大小比例为8：1，当经过15次minor gc后仍然存活在survivior中的对象将被转移到老年代。15次这个阈值可以修改。
	（2）老年代——full gc
	老年代和永久代采用的是“标记-清除-压缩（Mark-Sweep-Compact）”。标记的过程是找出当前还存活的对象，并进行标记；清除则遍历整个内存区域，找出其中需要进行回收的区域；而压缩则把存活对象的内存移动到整个内存区域的一端，使得另一端是一块连续的空闲区域，方便进行内存分配和复制。

java的new关键字在jvm层面都做了哪些事？
	1、虚拟机遇到一条new指令，首先去检查这个指令的参数能否在常量池中定位到一个类的符号引用，并且检查这个符号引用代表的类是否已经被加载、解析和初始化。如果没有，那么必须先执行类的初始化过程。
	2、类加载检查通过后，虚拟机为新生对象分配内存。对象所需内存大小在类加载完成后便可以完全确定，为对象分配空间无非就是从Java堆中划分出一块确定大小的内存而已。这个地方会有两个问题：
		（1）如果内存是规整的，那么虚拟机将采用的是指针碰撞法来为对象分配内存。意思是所有用过的内存在一边，空闲的内存在另外一边，中间放着一个指针作为分界点的指示器，分配内存就仅仅是把指针向空闲那边挪动一段与对象大小相等的距离罢了。如果垃圾收集器选择的是Serial、ParNew这种基于压缩算法的，虚拟机采用这种分配方式。
		（2）如果内存不是规整的，已使用的内存和未使用的内存相互交错，那么虚拟机将采用的是空闲列表法来为对象分配内存。意思是虚拟机维护了一个列表，记录上哪些内存块是可用的，再分配的时候从列表中找到一块足够大的空间划分给对象实例，并更新列表上的内容。如果垃圾收集器选择的是CMS这种基于标记-清除算法的，虚拟机采用这种分配方式。
	另外一个问题及时保证new对象时候的线程安全性。因为可能出现虚拟机正在给对象A分配内存，指针还没有来得及修改，对象B又同时使用了原来的指针来分配内存的情况。虚拟机采用了CAS配上失败重试的方式保证更新更新操作的原子性和TLAB两种方式来解决这个问题。
	3、内存分配结束，虚拟机将分配到的内存空间都初始化为零值（不包括对象头）。这一步保证了对象的实例字段在Java代码中可以不用赋初始值就可以直接使用，程序能访问到这些字段的数据类型所对应的零值。
	4、对对象进行必要的设置，例如这个对象是哪个类的实例、如何才能找到类的元数据信息、对象的哈希码、对象的GC分代年龄等信息，这些信息存放在对象的对象头中。
	5、执行<init>方法，把对象按照程序员的意愿进行初始化，这样一个真正可用的对象才算完全产生出来。

知道哪些jvm垃圾收集器？
答：
	（1）新生代收集器：
	Serial：
		单线程收集器，使用停止复制算法，使用一个线程进行GC，其它工作线程暂停。
	ParNew：
		多线程并行收集器，使用停止复制算法，Serial收集器的多线程版，用多个线程进行GC，其它工作线程暂停，关注缩短垃圾收集时间。
	Parallel Scavenge：
		多线程并行：使用停止复制算法，关注CPU吞吐量，即运行用户代码的时间/总时间，比如：JVM运行100分钟，其中运行用户代码99分钟，垃圾收集1分钟，则吞吐量是99%，这种收集器能最高效率的利用CPU，适合运行后台运算，适合用户交互，提高用户体验。
	（2）老年代收集器：
	Serial Old：
		单线程收集器，使用标记整理算法，使用单线程进行GC，其它工作线程暂停，jdk1.5之前与ParallelScavenge搭配使用。
	Parallel Old：
		多线程并行收集器，使用标记整理（与Serial Old不同，这里的整理是Summary（汇总）和Compact（压缩），汇总的意思就是将幸存的对象复制到预先准备好的区域，而不是像Sweep（清理）那样清理废弃的对象）算法，在Parallel Old执行时，仍然需要暂停其它线程。Parallel Old在多核计算中很有用。Parallel Old出现后（JDK1.6），与Parallel Scavenge配合有很好的效果，充分体现Parallel Scavenge收集器吞吐量优先的效果。
	CMS：
		多线程并发收集器，致力于获取最短回收停顿时间，使用标记清除算法，多线程，优点是并发收集（用户线程可以和GC线程同时工作），停顿小。
	（3）G1收集器：
	jdk1.7中提出的新收集器。

jvm是如何实现一次编译到处运行的?
答：
	jvm体系有很多门语言，不止java一个，比如scala，kotlin。
	这些jvm体系的语言有一个共同的特点就是平台无关性。
	这是由于jvm屏蔽了平台间的兼容问题，而所有的jvm系语言最后都将被编译为class文件。
	jvm负责解析class文件，然后利用本地操作系统来执行相关代码。
	所以jvm能够做到一次编译到处运行。

java内存模型？（注意与jvm内存结构不是一回事）
答：
	每个线程有自己的工作内存（映射到物理设备上就是高速缓存）
	线程工作时，首先从主内存中读取数据到自己的工作内存中，执行完运算后将数据写入自己的工作内存中，而不是直接与主内存交互。也因此线程中的数据同步到主内存是需要一定的时间的，这会造成线程安全问题。

十个线程同时++i会出现什么问题？为什么？如何解决?
答：
	问题：
		达不到预期结果，比预期结果值小。
	原因：
		和java内存模型有关，也和++i操作并非原子操作也有关。
		++i被编译成字节码后其实分为四个步骤执行
		1.getstatic //从主内存中读取i的值
		2.iconst_1 //定义常量1
		3.iadd //i增加1
		4.putstatic //把count结果同步到主内存
		这将导致多个线程可能同时读到相同的i值，然后重复的执行了+1的操作，导致i值只被增加了1次。
	解决方法：
		用AutomicInteger的自增方法来代替++i
		或者用synchronized关键字
		不能用volatile，因为volatile只能解决指令重排和可见性的问题，不能保证原子性。


automicinteger的自增实现原理？
答：
	代码：
	public final int getAndIncrement() {
	    for (;;) {
	        //先取出AtomicInteger的当前值
	        int current = get();
	        //对当前值加1操作
	        int next = current + 1;
	        //这里很关键，通过compareAndSet方法比较当前值有没有被其它线程修改过，若修改过返回false则再次进入compareAndSet方法判断
	        if (compareAndSet(current, next))
	            return current;
	    }
	}
	其中compareAndSet方法里面是调用了Unsafe类的compareAndSwapInt方法

如何在运行时估算一个java对象的大小？
	java对象结构组成：对象头Header + 实例数据Instance Data + 对齐填充Padding
	对象头：
		对象头在32位机上占8bytes，64位机上占16bytes。
	实例数据：
		计算实例数据所占空间大小，则可利用反射拿到java对象中所有变量，计算每个变量占用的内存，然后累加，如果变量类型是个数组则需循环累加。
		同样32位机上和64位机上的计算有所差异，因为引用Reference类型的变量在32位机上为4bytes，在64位机上则是8bytes。
	对齐填充：
		要保证(对象头 + 实例数据 + padding) % 8 == 0 且 0 <= padding < 8。
	指针压缩：
		jvm的指针压缩将会影响java对象的大小，开启指针压缩后header变为12bytes，引用类型变量变为4bytes。

有哪些可以监控jvm内存使用情况的工具?这些工具的实现原理？
答：
	1.jps   
		与unix上的ps类似，用来显示本地的java进程，可以查看本地运行着几个java程序，并显示他们的进程号。    
	2.jstat   
		一个极强的监视VM内存工具。可以用来监视VM内存内的各种堆和非堆的大小及其内存使用量。    
	3.jmap   
		打印出某个java进程（使用pid）内存内的，所有‘对象’的情况（如：产生那些对象，及其数量）。    
	4.jconsole   
		一个java GUI监视工具，可以以图表化的形式显示各种数据。并可通过远程连接监视远程的服务器VM。	
	这些工具的原理是利用jmx（Java Management Extensions，即Java管理扩展）机制实现。

线程和进程的区别？
答：
	进程：
		包括切换上下文的程序执行时间总和：
		进程 = CPU加载上下文 + CPU执行 + CPU保存上下文
	线程：
		CPU执行进程时是分成不同的小段执行的，比如一个文本编辑器程序，用户编辑文字时，程序需要并发的执行文字的自动保存，以及GUI的刷新。其中自动保存和GUI刷新就是2个线程，也就是说线程是进程实际的执行。
		从上面的公式可以看出来，在同一个进程的不同线程执行时，上下文是没有切换的，因此线程是共享同一个进程的上下文的。
	一个进程至少有一个线程。

java创建一个线程的几种方式？
答：
	Thread、Runnable、Callable或者ExecutorService线程池也勉强算

悲观锁、乐观锁、自旋锁？
答：
	悲观锁认为数据一定会被其他线程修改，因此直接锁住
	乐观锁认为数据不一定会被修改，因此在执行前保存一个标记位，执行后在更新数据前比较这个标记位是否被修改了，如果被修改则代表数据已经不是最新的版本了，丢掉重来。
	自旋锁则是因为线程被阻塞再唤醒的过程是耗时的，自旋锁在无法获得锁的情况下，不是将当前线程阻塞，而是让线程空转一会，在进行获取锁的尝试，这样能够提供效率。
	就比如你去上厕所，发现坑位有人，但是你从厕所走回去又太远（线程阻塞），因此你选择在厕所门口转一转（自旋），等待里边的人出来。
	当然也不能转太久，否则别人也这样的话厕所就站满人了（cpu耗尽），因此当发现等了很久都等不到时，需要自行离开。

独占锁、共享锁？读写锁？
答：
    独享锁是指该锁一次只能被一个线程所持有。
    共享锁是指该锁可被多个线程所持有。
    对于Java ReentrantLock而言，其是独享锁。但是对于Lock的另一个实现类ReadWriteLock，其读锁是共享锁，其写锁是独享锁。
    读锁的共享锁可保证并发读是非常高效的，读写，写读 ，写写的过程是互斥的。
    独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。
    对于Synchronized而言，当然是独享锁。

偏向锁、轻量级锁、重量级锁？
答：
    这三种锁是指锁的状态，并且是针对Synchronized。在Java 5通过引入锁升级的机制来实现高效Synchronized。这三种锁的状态是通过对象监视器在对象头中的字段来表明的。
    偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁。降低获取锁的代价。
    轻量级锁是指当锁是偏向锁的时候，被另一个线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，提高性能。
    重量级锁是指当锁为轻量级锁的时候，另一个线程虽然是自旋，但自旋不会一直持续下去，当自旋一定次数的时候，还没有获取到锁，就会进入阻塞，该锁膨胀为重量级锁。重量级锁会让其他申请的线程进入阻塞，性能降低。

公平锁/非公平锁？
答：
    公平锁是指多个线程按照申请锁的顺序来获取锁。
    非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。有可能，会造成优先级反转或者饥饿现象。
    对于Java ReentrantLock而言，通过构造函数指定该锁是否是公平锁，默认是非公平锁。非公平锁的优点在于吞吐量比公平锁大。
    对于Synchronized而言，也是一种非公平锁。由于其并不像ReentrantLock是通过AQS的来实现线程调度，所以并没有任何办法使其变成公平锁。

介绍下volatile与synchronized关键字的作用？
答：
	volatile禁止指令重排，保证内存可见性，是轻量级的
	synchronized实现并发锁，是重量级的

tomcat的实现原理？
	利用java的socket编程实现http协议

序列化和反序列化？
答：
	将对象转为二进制文件存储进行持久化或者进行网络通信（RPC——远程过程调用）的过程。
	可以利用序列化进行java对象的深拷贝。
	protostuff可以减小对象序列化后所占空间的大小。

线程有哪些状态？
答：
	五种状态：新建、就绪、运行、阻塞、死亡
	1.新建状态(New)：新创建了一个线程对象。
	2.就绪状态(Runnable)：线程对象创建后，其他线程调用了该对象的start()方法。
	该状态的线程位于“可运行线程池”中，变得可运行，只等待获取CPU的使用权。
	即在就绪状态的进程除CPU之外，其它的运行所需资源都已全部获得。
	3.运行状态(Running)：就绪状态的线程获取了CPU，执行程序代码。
	4.阻塞状态(Blocked)：阻塞状态是线程因为某种原因放弃CPU使用权，暂时停止运行。
	直到线程进入就绪状态，才有机会转到运行状态。
	5.死亡状态(Dead)：线程执行完了或者因异常退出了run()方法，该线程结束生命周期。

线程阻塞分为哪几种情况？
答：
	三种情况：等待阻塞、同步阻塞、其他阻塞
	1.等待阻塞：运行的线程执行wait()方法，该线程会释放占用的所有资源，JVM会把该线程放入“等待池”中。
	进入这个状态后，是不能自动唤醒的，必须依靠其他线程调用notify()或notifyAll()方法才能被唤醒，
	2.同步阻塞：运行的线程在获取对象的同步锁时，若该同步锁被别的线程占用，则JVM会把该线程放入“锁池”中。
	3.其他阻塞：运行的线程执行sleep()或join()方法，或者发出了I/O请求时，JVM会把该线程置为阻塞状态。
	当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。

有哪些类型的线程池构造方法？
答：
	1.Executors.newSingleThreadExecutor()创建单线程任务线程池
	2.Executors.newFixedThreadPool(nThreads)创建固定数量线程线程池
	3.Executors.newCachedThreadPool()创建以默认60秒为空闲时间的缓存线程池，核心线程数为0
	4.Executors.newScheduledThreadPool(corePoolSize)创建可以控制执行时间的线程池
	其中主要使用FixedThreadPool和CachedThreadPool:
	FixedThreadPool:
		FixedThreadPool中最多只有固定数目线程存在，一个线程实例请求加入FixedThreadPool时，如果该实例不存在，且没有达到线程池数目上限，则会创建一个实例，否则会先加入等待序列，当FixedThreadPool中有一个线程停止并移出线程池后，线程实例才能加入线程池，FixedThreadPool没有超时机制,适用于稳定且并发线程任务
	CachedThreadPool:
		一个线程实例加入CachedThreadPool时，如果该线程实例不存在CachedThreadPool，则创建一个，CachedThreadPool中线程实例默认超时时间为60s，超过这个时间，线程实例停止并被移出CachedThreadPool，适用于生存期短、异步的线程任务。

线程池有哪些重要的配置？
	corePoolSize - 池中所保存的线程数，包括空闲线程。
	maximumPoolSize-池中允许的最大线程数。
	keepAliveTime - 当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间。
		unit - keepAliveTime 参数的时间单位。
	workQueue - 执行前用于保持任务的队列。此队列仅保持由 execute方法提交的 Runnable任务。
	threadFactory - 执行程序创建新线程时使用的工厂。
	handler - 由于超出线程范围和队列容量而使执行被阻塞时所使用的处理程序。

线程池中的线程数量达到最大值后会怎样？
答：
	任务队列没有大小限制时：
		1.如果线程数量<=核心线程数量，那么直接启动一个核心线程来执行任务，不会放入队列中。
		2.如果线程数量>核心线程数，但<=最大线程数，并且任务队列是LinkedBlockingDeque的时候，超过核心线程数量的任务会放在任务队列中排队。
		3.如果线程数量>核心线程数，但<=最大线程数，并且任务队列是SynchronousQueue的时候，线程池会创建新线程执行任务，这些任务也不会被放在任务队列中。这些线程属于非核心线程，在任务完成后，闲置时间达到了超时时间就会被清除。
		4.如果线程数量>核心线程数，并且>最大线程数，当任务队列是LinkedBlockingDeque，会将超过核心线程的任务放在任务队列中排队。也就是当任务队列是LinkedBlockingDeque并且没有大小限制时，线程池的最大线程数设置是无效的，他的线程数最多不会超过核心线程数。
		5.如果线程数量>核心线程数，并且>最大线程数，当任务队列是SynchronousQueue的时候，会因为线程池拒绝添加任务而抛出异常。
	任务队列大小有限时:
		1.当LinkedBlockingDeque塞满时，新增的任务会直接创建新线程来执行，当创建的线程数量超过最大线程数量时会抛异常。
		2.SynchronousQueue没有数量限制。因为他根本不保持这些任务，而是直接交给线程池去执行。当任务数量超过最大线程数时会直接抛异常。

业务高峰过后，线程池中的线程数量多余的话会怎样？
答：
	多余的线程会被释放掉，直到线程数回归corePoolSize，还可以进行配置，使得线程数归为0。

线程池容量能不能动态调整？
答：
	可以。
	ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()，
	setCorePoolSize：设置核心池大小
	setMaximumPoolSize：设置线程池最大能创建的线程数目大小
　　当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。